<!-- IMPORTANT: Update the placeholders (ACTOR_VERB, EXPECTED, ACTUAL, WHY_IT_FAILED, CODE_SNIPPET) in this template to reflect the specific test result. -->

# 🧪 Test Results: {test_name}

> Test execution results for {test_suite/feature} documenting {pass/fail} status with detailed findings. Captures expected vs actual behavior, failure analysis, and proposed fixes to facilitate debugging and resolution.

## 🤖 AI Agent Context
> 💡 *Essential information for the AI agent to understand the context of this test result, especially if further analysis, bug reporting, or re-testing is required.*

## 📚 Relevant Project Files & Code
> 💡 *List the specific code files, test scripts, or feature modules related to this test.*

*   `[path/to/tested_feature_code.ext]` - (Relevance: The code that was under test)
*   `[path/to/test_script.ext]` - (Relevance: The test script that produced this result)
*   *Example: `src/features/login/services/auth_service.test.js` - (Relevance: Unit test file for authentication)*

## 🌐 Relevant Documentation & Links
> 💡 *List any links to user stories, requirements documents, bug reports, or design specifications that define the expected behavior.*

*   `[Link to User Story/Requirement ID]` - (Relevance: Defines the expected behavior)
*   `[Link to related Bug Report if this is a regression or re-test]` - (Relevance: History of the issue)
*   *Example: `https://your-tracking-tool.com/issues/BUG-123` - (Relevance: Original bug report)*

## 💡 Other Key Information
> 💡 *Include any other critical context, such as the test environment, specific test data used, or any unusual conditions observed during the test.*

*   `[Context point 1: e.g., Test was run on Staging Environment, Version 1.2.3.]`
*   `[Context point 2: e.g., Test data used: user='test@example.com', password='password123'.]`
*   *Example: This failure is intermittent and seems to occur under high load.*

## 📝 Activity: ACTOR_VERB
💎 Expected: EXPECTED
🧱 Actual: ACTUAL
💭 Reason: WHY_IT_FAILED
🔧 Proposed Fix: CODE_SNIPPET